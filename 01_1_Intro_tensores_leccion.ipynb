{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes neuronales con Pytorch\n",
    "\n",
    "@jivg.org\n",
    "\n",
    "## Introducción\n",
    "\n",
    "¡Bienvenidos a esta serie de prácticas diseñadas para aprender PyTorch, uno de los frameworks más potentes y flexibles para el desarrollo de proyectos en aprendizaje profundo!\n",
    "\n",
    "PyTorch ha ganado popularidad por su enfoque intuitivo, su integración con Python y su soporte para la creación de modelos complejos de redes neuronales. Este conjunto de prácticas te guiará desde los conceptos básicos hasta la implementación de redes neuronales avanzadas, brindándote las herramientas necesarias para abordar problemas reales en el mundo del aprendizaje automático.\n",
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/irvingvasquez/practicas_pytorch/blob/master/01_Intro_redes_y_tensores.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensores en Pytorch\n",
    "\n",
    "Los tensores son una generalización de los vectores y matrices. Cuando hablamos de un tensor de una dimensión nos estamos refierendo a un vector que puede tener $n$ elementos. Podemos tener tensores de varias dimensiones, por ejemplo una matriz 2D sería un tensor 2D y así sucesivamente. Los tensores son la base de muchos paquetes de para programar deep learning, debido a que las redes neuronales son ¡un montón de operaciones matriciales!, además mantienen la conección en el grafo y permiten la implementación del gradiente descendiente. Asi que es indispensable tener una representación adecuada para reducir el tiempo de entrenamiento. \n",
    "\n",
    "Sin más preámbulo vayamos a la programación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n",
      "1.12.0\n"
     ]
    }
   ],
   "source": [
    "# Primero importemos los paquetes necesarios\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "print(np.__version__)\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción\n",
    "\n",
    "Comenzemos por explorar el uso de tensores. Algunas funciones básias para construir los tensores son:\n",
    "\n",
    "**`torch.tensor`**:\n",
    "   - Esta función se usa para crear un tensor directamente a partir de datos. Ejemplo de uso:\n",
    "      ```python\n",
    "      data = [[1, 2], [3, 4]]\n",
    "      tensor = torch.tensor(data)\n",
    "      ```\n",
    "\n",
    " **`torch.ones`**:\n",
    "   - Crea un tensor lleno de unos con las dimensiones especificadas. Ejemplo de uso:\n",
    "      ```python\n",
    "      tensor = torch.ones(2, 4)  # Crea un tensor 2x4 lleno de unos\n",
    "      ```\n",
    "\n",
    "**`torch.arange`**:\n",
    "   - Genera un tensor con valores en un rango especificado con un paso determinado. Ejemplo de uso:\n",
    "      ```python\n",
    "      tensor = torch.arange(0, 10, 2)  # Crea un tensor con valores [0, 2, 4, 6, 8]\n",
    "      ```\n",
    "\n",
    "**`torch.randn`**:\n",
    "   - Genera un tensor con valores aleatorios distribuidos normalmente (media 0, desviación estándar 1). Ejemplo de uso:\n",
    "      ```python\n",
    "      tensor = torch.randn(3, 3)  # Crea un tensor 3x3 con valores aleatorios de una distribución normal\n",
    "      ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[ 1.1353, -0.6624, -1.1494],\n",
      "        [ 0.2382,  0.2050,  0.3718],\n",
      "        [ 1.5074, -0.1585,  1.0304]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor de 4 por 2 elementos relleno de unos\n",
    "y = torch.ones(4,2)\n",
    "# Tensor de 3 por 3 elementos relleno de valores aleatorios\n",
    "r = torch.randn(3,3)\n",
    "\n",
    "print(y)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En PyTorch, puedes realizar una amplia variedad de operaciones básicas con tensores. A continuación veremos algunas de las operaciones más comunes:\n",
    "\n",
    "- Adición. Se usa el operador `+`\n",
    "- Sustracción. Se usa el operador `-`\n",
    "- Multiplicación elemento por elemento. Operador `*`\n",
    "- División elemento por elemento. Operador `/`\n",
    "- Exponenciación. Operador `**`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suma: tensor([[3., 3.],\n",
      "        [3., 3.],\n",
      "        [3., 3.],\n",
      "        [3., 3.]])\n",
      "Resta: tensor([[2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.],\n",
      "        [2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "# Operaciónes entre tensores\n",
    "# suma de tensores\n",
    "z = y + y + y\n",
    "print(\"Suma:\", z)\n",
    "\n",
    "# resta de tensores\n",
    "z = z - y\n",
    "print(\"Resta:\", z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acceder a los elementos de un tensor en PyTorch es muy similar a cómo se accede a los elementos en una lista o un arreglo de NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n",
      "tensor([2., 2.])\n",
      "tensor([2., 2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "# acceder a un elemento del tensor\n",
    "print(z[1][1])\n",
    "\n",
    "# acceder a la segunda fila\n",
    "print(z[1])\n",
    "\n",
    "# acceder a la segunda columna\n",
    "print(z[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.],\n",
       "        [2.],\n",
       "        [2.],\n",
       "        [2.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observa el siguiete código y trata de entender que hace\n",
    "z[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La notación z[:, 1:] en PyTorch se utiliza para seleccionar una porción específica de un tensor. Aquí está el desglose:\n",
    "- : indica que se seleccionan todas las filas del tensor.\n",
    "- 1: indica que se seleccionan todas las columnas desde la segunda columna en adelante (recordando que los índices en Python son cero-basados).\n",
    "Por lo tanto, z[:, 1:] selecciona todas las filas y todas las columnas desde la segunda columna hasta el final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape\n",
    "\n",
    "Una de las cosas más comunes que realizaŕas con los tensores es consultar su 'forma' es decir, la cantidad de elementos que hay en él, para tal función existe *.size()* \n",
    "\n",
    "Si deseamos cambiar la forma del tensor entonces utilizaremos *.resize_()* Observa que el guión bajo indica que se va a modificar el tensor en sí, si no utilizamos el guión bajo se creará un nuevo tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.0000e+00, 2.0000e+00, 2.0000e+00],\n",
       "        [2.0000e+00, 2.0000e+00, 2.0000e+00],\n",
       "        [2.0000e+00, 2.0000e+00, 1.0378e-38]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.resize_(3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasando Tensores a Numpy\n",
    "\n",
    "Antes de hacer el entrenamiento de una red es muy probable que tengamos que hacer un preprocesamiento de los datos. Usualmente, el procesamiento se hace en numpy por facilidad además que tenemos muchísimas herramientas disponibles. Afortunadamente, pytorch provee una funciones para poder convertir entre formatos de forma casi directa. Para convetir de numpy a tensor usamos *torch.from_numpy()* y para retornar de torch a numpy utilizamos el método *.numpy()*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88287308 0.16807635 0.31020138]\n",
      " [0.91777182 0.40180744 0.70725716]\n",
      " [0.54134548 0.91257211 0.25928722]\n",
      " [0.15786873 0.57274718 0.6367663 ]]\n"
     ]
    }
   ],
   "source": [
    "# generemos un array en numpy\n",
    "a = np.random.rand(4,3)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8829, 0.1681, 0.3102],\n",
      "        [0.9178, 0.4018, 0.7073],\n",
      "        [0.5413, 0.9126, 0.2593],\n",
      "        [0.1579, 0.5727, 0.6368]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# convertir a pytorch\n",
    "A = torch.from_numpy(a)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88287308 0.16807635 0.31020138]\n",
      " [0.91777182 0.40180744 0.70725716]\n",
      " [0.54134548 0.91257211 0.25928722]\n",
      " [0.15786873 0.57274718 0.6367663 ]]\n"
     ]
    }
   ],
   "source": [
    "# convertir a numpy\n",
    "b = A.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advertencia! Ten cuidado por que resulta que las variables convertidas de pytorch a numpy comparte memoria asi que si modificas uno se modificará el otro!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8829, 0.1681, 0.3102],\n",
      "        [0.9178, 0.4018, 0.7073],\n",
      "        [0.5413, 0.9126, 0.2593],\n",
      "        [0.1579, 0.5727, 0.6368]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.7657, 0.3362, 0.6204],\n",
      "        [1.8355, 0.8036, 1.4145],\n",
      "        [1.0827, 1.8251, 0.5186],\n",
      "        [0.3157, 1.1455, 1.2735]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# multipliquemos el tensor\n",
    "A.mul_(2)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ahora observemos el array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.76574615, 0.33615271, 0.62040276],\n",
       "       [1.83554364, 0.80361487, 1.41451433],\n",
       "       [1.08269096, 1.82514422, 0.51857444],\n",
       "       [0.31573746, 1.14549436, 1.2735326 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funciones básicas\n",
    "\n",
    "PyTorch proporciona una serie de funciones básicas para realizar operaciones aritméticas y de manipulación de tensores.\n",
    "\n",
    "- **`torch.add`**:\n",
    "   - Suma dos tensores elemento por elemento. Uso:\n",
    "      ```python\n",
    "      a = torch.tensor([1, 2, 3])\n",
    "      b = torch.tensor([4, 5, 6])\n",
    "      c = torch.add(a, b)  # c = [5, 7, 9]\n",
    "      ```\n",
    "- **`torch.sub`**:\n",
    "   - Resta dos tensores elemento por elemento.\n",
    "      ```python\n",
    "      c = torch.sub(a, b)  # c = [-3, -3, -3]\n",
    "      ```\n",
    "- **`torch.dot`:**\n",
    "   - Realiza el producto punto de dos vectores.\n",
    "      ```python\n",
    "      c = torch.dot(a, b) \n",
    "      ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 3., 4.], dtype=torch.float64)\n",
      "tensor([0.1000, 0.1000, 0.2000], dtype=torch.float64)\n",
      "tensor([1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Implementa un perceptrón\n",
    "x_np = np.array([2.0, 3.0, 4.0])\n",
    "w_np = np.array([0.1, 0.1, 0.2])\n",
    "b_np = np.array([1.0])\n",
    "\n",
    "# Convierte los vectores a tensores de pytorch\n",
    "X = torch.from_numpy(x_np)\n",
    "print(X)\n",
    "W = torch.from_numpy(w_np)\n",
    "print(W)\n",
    "B = torch.from_numpy(b_np)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementando el perceptrón\n",
    "\n",
    "<img src=\"archivos/simple_neuron.png\" width=400>\n",
    "Imagen tomada de [Udacity]\n",
    "\n",
    "Podemos ver la salida del perceptrón como una secuencia de operaciones, primero se calcula $h$ a partir del producto punto, entre las entradas $X$ y los pesos $W$, sumado a el sesgo $b$, es decir\n",
    "\n",
    "$$h = MX + b$$\n",
    "\n",
    "despúes se 'pasa' $h$ por una función de activación que transforma el valor,\n",
    "\n",
    "$$y = f(h)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# realiza las operaciones necesarias y calcula la combinación lineal h\n",
    "# algunas funciones útiles son torch.add() y torch.dot()\n",
    "# y = W*X + B\n",
    "H =  torch.add(torch.dot(W,X),B)\n",
    "print(H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9801], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Pasa h por la función de activación segmoide torch.sigmoid()\n",
    "Y = torch.tanh(H)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9800964]\n"
     ]
    }
   ],
   "source": [
    "# Finalmente regresamos el tensor a un array de numpy\n",
    "y_np = Y.numpy()\n",
    "print(y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_1_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
