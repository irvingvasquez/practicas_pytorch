{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lectura de imágenes\n",
    "\n",
    "En este notebook veremos como introducir imágenes a nuestra red neuronal.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "\n",
    "Existen multiples formas para hacerlo, pero en este tutorial utilizaremos la función *dataset.ImageFolder* incorporada en el paquete *torchvision*. La forma rápida de leer un conjunto de imágenes es\n",
    "\n",
    "```python\n",
    "dataset = datasets.ImageFolder('directorio/', transform=transformacion)\n",
    "```\n",
    "\n",
    "la función *ImageFolder* espera que dentro del directorio los archivos esté organizados por folderes, donde cada folder contiene las imagenes de una clase en específico.\n",
    "\n",
    "En este ejemplo usaré una base de datos propia que contiene dos clases, cactus y no_cactus. La base de datos tiene dos carpetas con los nombres *cactus* y *no_cactus*.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformaciones\n",
    "\n",
    "Usualmente las imagenes que leas estarán en un tamaño diferente al que necesitas para la red, asi que es necesario convertirlas a un formato adecuado, además será necesario convertirlas a tensores de pytorch. Todo esto lo podemos hacer con la función *transforms.Compose()*, en la cual podemos apilar las transformaciones necesarias. Por ejemplo,\n",
    "\n",
    "```python\n",
    "transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                 transforms.CenterCrop(224),\n",
    "                                 transforms.ToTensor()])\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos paquetes\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directorio de la carpeta\n",
    "directorio = 'cactus_dataset2'\n",
    "\n",
    "# aplicaré una serie de transformaciones\n",
    "# 1. escalar las imágenes a 32 x 32 pixeles\n",
    "# 2. convertir a tensores\n",
    "transformaciones = transforms.Compose([transforms.Resize(32),\n",
    "                               transforms.CenterCrop(32),\n",
    "                               transforms.ToTensor()])  \n",
    "datos = datasets.ImageFolder(directorio, transformaciones) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader\n",
    "\n",
    "Image folder se encarga de las imágenes, sin embargo todavía es necesario otro objeto, el *DataLoader* quien se encarga de leer los ejemplos por lotes (batches) junto con su correspondiente etiqueta. En el objeto *DataLoader* puedes especificar diversos parametros como el tamaño del lote si los datos son mezclados (*suffled*) despúes de cada época, entre otras opciones. Por ejemplo,\n",
    "\n",
    "```python\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "```\n",
    "\n",
    "Para iterar sobre los datos podemos hacer:\n",
    "\n",
    "```python\n",
    "# Looping through it, get a batch on each loop \n",
    "for images, labels in dataloader:\n",
    "    pass\n",
    "\n",
    "# Get one batch\n",
    "images, labels = next(iter(dataloader))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crear el objeto dataloader\n",
    "cargador = torch.utils.data.DataLoader(datos, batch_size=32, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to test your data loader\n",
    "images, labels = next(iter(cargador))\n",
    "helper.imshow(images[0], normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data'\n",
    "\n",
    "# TODO: Define transforms for the training data and testing data\n",
    "train_transforms = \n",
    "\n",
    "test_transforms = \n",
    "\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(data_dir + '/train', transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + '/test', transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=32)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this to the trainloader or testloader \n",
    "data_iter = iter(testloader)\n",
    "\n",
    "images, labels = next(data_iter)\n",
    "fig, axes = plt.subplots(figsize=(10,4), ncols=4)\n",
    "for ii in range(4):\n",
    "    ax = axes[ii]\n",
    "    helper.imshow(images[ii], ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
